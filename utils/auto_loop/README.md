Auto Loop 实验编排器（轻量）

用途
- 批量排队小步数训练（如 2K steps），可设置并发与固定 GPU 绑核。
- 默认离线 W&B，输出到本地 output_dir；可切换在线 W&B。
- 每个作业结束后解析 wandb-history.jsonl，生成精简统计并累计到 JSON/Markdown 报告。
- 可按规则自动生成下一轮实验配置，形成多轮迭代。

涉及脚本
- autorun.py：主循环调度器。按“accelerate launch … src/lerobot/scripts/lerobot_train.py”启动；
  - 每个 slot 设置独立 CUDA_VISIBLE_DEVICES；
  - 记录离线/在线 W&B；
  - 作业结束后解析本地 wandb 历史，汇总到 reports/data/autorun_summary.json；
  - 打开 --decide 时，按 rules.py 的启发式从已完成作业生成下一轮候选配置，并继续跑。
- rules.py：根据关键指标（例如 L1、OT 质量和/对角、OT 成本、梯度范数）提出若干“配置改动”。支持点号路径 + @set/@mul/@add，含列表通配符（features.*.weight_label）。
- common.py：解析本地 wandb 历史（wandb-history.jsonl），按 first/last/best/delta/% 生成简明统计。
- analyze_offline.py：扫描 outputs/train/**/wandb/**，生成本地离线汇总 JSON。
- analyze_wandb.py：在线 W&B 汇总（需要网络与 WANDB_API_KEY，可选）。
- generate_and_run.py：从一个基线 JSON 生成单个变体（点号编辑），可选择立即启动该单跑。

输出位置
- 训练输出目录：outputs/train/…（每个作业各自的 output_dir，内部含 wandb/）
- 轮次累计 JSON：src/lerobot/scripts/train_config/reports/data/autorun_summary.json
- 轮次 Markdown 摘要：src/lerobot/scripts/train_config/reports/act_ot.md（附每个 cfg、out 路径与关键指标；若日志里发现 W&B URL 也会附上）

安全默认
- 未指定时，默认强制 W&B 离线（--wandb.mode=offline，禁止 artifact 以减少权限噪音）。
- 不会预创建 output_dir（训练脚本会校验目录必须不存在）。
- 自动把 W&B 缓存指向 .wandb_cache/，避免写入家目录权限问题。

快速开始：3 轮 ACT-OT（并发 4，GPU=0,1,6,7，steps=2K）
- 最推荐：第一轮就占满 4 个 slot（基线 + 3 个小变体），保证每轮稳定 4 并发。

  1) 先生成 3 个变体（只写文件，不执行）：

     python -m utils.auto_loop.generate_and_run \
       --base-cfg src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline.json \
       --reason "reg+tau" \
       --changes 'ot.loss_config.reg@mul=1.5' 'ot.loss_config.tau_src@set=1.0' 'ot.loss_config.tau_tgt@set=1.0' 'ot.lambda_ot@set=0.12'

     python -m utils.auto_loop.generate_and_run \
       --base-cfg src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline.json \
       --reason "tau=2, lam=0.15" \
       --changes 'ot.loss_config.tau_src@set=2.0' 'ot.loss_config.tau_tgt@set=2.0' 'ot.lambda_ot@set=0.15' 'ot.loss_config.features.*.weight_label@mul=0.5'

     python -m utils.auto_loop.generate_and_run \
       --base-cfg src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline.json \
       --reason "tau=5, action=0.005" \
       --changes 'ot.loss_config.tau_src@set=5.0' 'ot.loss_config.tau_tgt@set=5.0' 'ot.lambda_ot@set=0.10' 'ot.loss_config.features.*.weight_label@set=0.005'

  2) 用 4 份配置跑 3 轮（在线 W&B 示例）：

     python utils/auto_loop/autorun.py \
       --cfgs \
         src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline.json \
         <三个上面生成的新 cfg 路径> \
       --steps 2000 --log-freq 50 --eval-freq 200 \
       --concurrency 4 --gpus 0,1,6,7 \
       --decide --variants-per-run 1 --rounds 3 \
       --exec --wandb-online --wandb-entity <你的entity> --wandb-project <你的project>

  说明：
  - 下一轮会在“本轮全部作业结束后”自动生成并启动；
  - 在线/离线均会在 output_dir/wandb/latest-run/files 下写本地历史文件，autorun 依此解析；
  - 如果看到 “No next-round jobs were generated by rules; stopping.”，常见原因是本轮作业未产出可解析的历史（如提前报错退出）。请先检查各 slot 日志与输出目录。

手动单进程（命令格式示例）
- 直接手动跑一个作业时，推荐：

  CUDA_VISIBLE_DEVICES=0 accelerate launch --num_processes 1 \
    src/lerobot/scripts/lerobot_train.py \
    --config_path=src/lerobot/scripts/train_config/act_fr3_ot.json

  autorun.py 内部就是按该格式为每个并发 slot 绑定一张 GPU 并启动。

规则（简述）
- pi_sum 很小：增大 reg、增大 tau、扩大/上限窗口；
- pi 高但成本不降：降低 label 权重、稍降 lambda_ot；
- L1 停滞：小幅增大学习率与 batch；
- grad_norm 过大：增加正则或降低学习率；
- 都不触发：给出“温和 OT”默认变体。

排障要点
- 未生成下一轮：
  1) 先等本轮所有作业结束（autorun 才会汇总并决策）；
  2) 检查每个 output_dir 下是否存在 wandb/latest-run/files/wandb-history.jsonl；
  3) 查 .codex_tmp/slot*_*.log 是否有报错；
  4) 如需仅汇总现有离线日志，可运行 analyze_offline.py。

-----------------
我已基于第 1 轮的 4 个作业各生成 1 个“温和 OT”变体，并写好了待跑清单。

  已生成的下一轮配置

  - src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline_0j57ea.json
  - src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline_cqm6fm_idj1ci.json
  - src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline_f41by4_v9z4nx.json
  - src/lerobot/scripts/train_config/act_fr3_ot_99_20_baseline_16lch8_qllxw3.json

  已写入列表

  - .codex_tmp/next_round_cfgs_auto.txt

  如何手动启动 Round 2（并发 4，GPU=0,1,6,7，steps=2K，在线 W&B）

  - 推荐命令：
      - cfgs=$(cat .codex_tmp/next_round_cfgs_auto.txt | tr '\n' ' '); echo "$cfgs"
      - setsid nohup python utils/auto_loop/autorun.py --cfgs $cfgs --steps 2000 --log-freq 50 --eval-freq 200 --concurrency 4 --gpus 0,1,6,7 --decide --rounds 2 --variants-per-run 1 --exec
        --wandb-online --wandb-entity kjust-pinduoduo --wandb-project lerobot > .codex_tmp/autorun_round2.log 2>&1 & echo $! && sleep 2 && tail -n 120 .codex_tmp/autorun_round2.log

  说明

  - 之所以上一轮没有自动进入下一轮，是因为在线 W&B 情况下本地可能没有 wandb-history.jsonl。我已在 utils/auto_loop/common.py 增加了容错：若缺失 history.jsonl，就回退读取 wandb-summary.json，
    不影响训练，只用于本地汇总。
  - 我没有改动你的训练脚本或命令风格；autorun 仍按 CUDA_VISIBLE_DEVICES + accelerate launch 的格式启动。

  需要我也顺带生成 Round 3 的候选清单（等 Round 2 完成后再给出），还是你跑完 Round 2 再通知我继续？

  请用你熟悉的 nohup 启动 Round 2

  - 先取变量：
      - cfgs=$(cat .codex_tmp/next_round_cfgs_auto.txt | tr '\n' ' '); echo "$cfgs"
  - 启动：
      - setsid nohup python utils/auto_loop/autorun.py --cfgs $cfgs --steps 2000 --log-freq 50 --eval-freq 200 --concurrency 4 --gpus 0,1,6,7 --decide --rounds 2 --variants-per-run 1 --exec
        --wandb-online --wandb-entity kjust-pinduoduo --wandb-project lerobot > .codex_tmp/autorun_round2.log 2>&1 & echo $! && sleep 2 && tail -n 120 .codex_tmp/autorun_round2.log